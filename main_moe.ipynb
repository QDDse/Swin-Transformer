{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4babdd11-0989-47a9-ae92-70a9b23f19cf",
   "metadata": {},
   "source": [
    "# This is a notebook based on the swin-moe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9850331a-41a7-4d6b-abf6-d3b86846ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n"
     ]
    }
   ],
   "source": [
    "from tutel import system\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "\n",
    "from config import get_config\n",
    "from models import build_model\n",
    "from data import build_loader\n",
    "from lr_scheduler import build_scheduler\n",
    "from optimizer import build_optimizer\n",
    "from logger import create_logger\n",
    "from utils import NativeScalerWithGradNormCount, reduce_tensor\n",
    "from utils_moe import load_checkpoint, load_pretrained, save_checkpoint, auto_resume_helper, hook_scale_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83163d94-5cdb-45d0-833a-5b3e3b279841",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tutel import moe as tutel_moe\n",
    "except:\n",
    "    tutel_moe = None\n",
    "    print(\"Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6425923-2f77-46c8-9f1f-3d1343185bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.__version__ >= '1.8.0', \"DDP-based MoE requires Pytorch >= 1.8.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96aa527-e124-4043-a864-b356276542cb",
   "metadata": {},
   "source": [
    "## Gshard-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c468942-d181-4764-8e82-afd36135fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "def _one_hot_with_dtype(data, num_classes, dtype, hot_value=1):\n",
    "    result = torch.zeros([data.size(0), num_classes], device=data.device, dtype=dtype)\n",
    "    result.scatter_(1, data.unsqueeze(-1), hot_value)\n",
    "    return result\n",
    "\n",
    "def gshard_loss(scores_w_noise, top_ids):\n",
    "    num_samples, num_global_experts = int(scores_w_noise.size(0)), int(scores_w_noise.size(1))\n",
    "    mask = _one_hot_with_dtype(top_ids[:, 0], num_global_experts, dtype=scores_w_noise.dtype,\n",
    "        hot_value=num_global_experts / num_samples)\n",
    "    me = torch.sum(scores_w_noise, dim=0)\n",
    "    ce = torch.sum(mask, dim=0)\n",
    "    l_aux = torch.sum(me * ce) / num_samples\n",
    "    return l_aux\n",
    "\n",
    "def load_importance_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise):\n",
    "    def load_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise):\n",
    "        assert gate_noise > 0, \"`gate_noise` must be > 0 for normalization in load_importance_loss().\"\n",
    "        normal = Normal(\n",
    "            torch.tensor([0.0], device=scores_wo_noise.device),\n",
    "            torch.tensor([gate_noise / num_global_experts], device=scores_wo_noise.device),\n",
    "        )\n",
    "        threshold = topk_logits[:, -1].view(-1, 1).float()\n",
    "        diff = scores_wo_noise.float() - threshold.float()\n",
    "        prob = normal.cdf(diff)\n",
    "        Load = prob.sum(0)\n",
    "        l_load = Load.float().var() / (Load.float().mean() ** 2 + 1e-10)\n",
    "        return l_load\n",
    "\n",
    "    def importance_loss(scores_wo_noise):\n",
    "        Impi = scores_wo_noise.float().sum(0)\n",
    "        l_imp = Impi.float().var() / (Impi.float().mean() ** 2 + 1e-10)\n",
    "\n",
    "        return l_imp\n",
    "\n",
    "    l_imp = importance_loss(scores_wo_noise)\n",
    "    l_load = load_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise)\n",
    "    return (l_imp + l_load) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece0e1d6-f779-400c-b4ac-87646436721b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_343653/3370800231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mget_backend\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \"\"\"\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    427\u001b[0m     \"\"\"\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0;34m\"Default process group has not been initialized, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"please make sure to call init_process_group.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "dist.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9fc40c-a96a-46b0-a9d2-0deac93003f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd424f-6904-4146-a20c-1f42af70c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.init_process_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
