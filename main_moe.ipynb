{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4babdd11-0989-47a9-ae92-70a9b23f19cf",
   "metadata": {},
   "source": [
    "# This is a notebook based on the swin-moe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9850331a-41a7-4d6b-abf6-d3b86846ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n"
     ]
    }
   ],
   "source": [
    "from tutel import system\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "\n",
    "from config import get_config\n",
    "from models import build_model\n",
    "from data import build_loader\n",
    "from lr_scheduler import build_scheduler\n",
    "from optimizer import build_optimizer\n",
    "from logger import create_logger\n",
    "from utils import NativeScalerWithGradNormCount, reduce_tensor\n",
    "from utils_moe import load_checkpoint, load_pretrained, save_checkpoint, auto_resume_helper, hook_scale_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83163d94-5cdb-45d0-833a-5b3e3b279841",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tutel import moe as tutel_moe\n",
    "except:\n",
    "    tutel_moe = None\n",
    "    print(\"Tutel has not been installed. To use Swin-MoE, please install Tutel; otherwise, just ignore this.\")\n",
    "    assert torch.__version__ >= '1.8.0', \"DDP-based MoE requires Pytorch >= 1.8.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b4a854-f5a5-4d93-b932-38d17d36c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('Swin Transformer training and evaluation script', add_help=False)\n",
    "    parser.add_argument('--cfg', type=str, required=True, metavar=\"FILE\", help='path to config file', )\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
    "        default=None,\n",
    "        nargs='+',\n",
    "    )\n",
    "\n",
    "    # easy config modification\n",
    "    parser.add_argument('--batch-size', type=int, help=\"batch size for single GPU\")\n",
    "    parser.add_argument('--data-path', type=str, help='path to dataset')\n",
    "    parser.add_argument('--zip', action='store_true', help='use zipped dataset instead of folder dataset')\n",
    "    parser.add_argument('--cache-mode', type=str, default='part', choices=['no', 'full', 'part'],\n",
    "                        help='no: no cache, '\n",
    "                             'full: cache all data, '\n",
    "                             'part: sharding the dataset into nonoverlapping pieces and only cache one piece')\n",
    "    parser.add_argument('--pretrained',\n",
    "                        help='pretrained weight from checkpoint, could be imagenet22k pretrained weight')\n",
    "    parser.add_argument('--resume', help='resume from checkpoint')\n",
    "    parser.add_argument('--accumulation-steps', type=int, help=\"gradient accumulation steps\")\n",
    "    parser.add_argument('--use-checkpoint', action='store_true',\n",
    "                        help=\"whether to use gradient checkpointing to save memory\")\n",
    "    parser.add_argument('--disable_amp', action='store_true', help='Disable pytorch amp')\n",
    "    parser.add_argument('--amp-opt-level', type=str, choices=['O0', 'O1', 'O2'],\n",
    "                        help='mixed precision opt level, if O0, no amp is used (deprecated!)')\n",
    "    parser.add_argument('--output', default='output', type=str, metavar='PATH',\n",
    "                        help='root of output folder, the full path is <output>/<model_name>/<tag> (default: output)')\n",
    "    parser.add_argument('--tag', help='tag of experiment')\n",
    "    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n",
    "    parser.add_argument('--throughput', action='store_true', help='Test throughput only')\n",
    "\n",
    "    # distributed training\n",
    "    parser.add_argument(\"--local_rank\", type=int, required=True, help='local rank for DistributedDataParallel')\n",
    "\n",
    "    args, unparsed = parser.parse_known_args([])\n",
    "\n",
    "    config = get_config(args)\n",
    "\n",
    "    return args, config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96aa527-e124-4043-a864-b356276542cb",
   "metadata": {},
   "source": [
    "## Gshard-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c468942-d181-4764-8e82-afd36135fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "def _one_hot_with_dtype(data, num_classes, dtype, hot_value=1):\n",
    "    result = torch.zeros([data.size(0), num_classes], device=data.device, dtype=dtype)\n",
    "    result.scatter_(1, data.unsqueeze(-1), hot_value)\n",
    "    return result\n",
    "\n",
    "def gshard_loss(scores_w_noise, top_ids):\n",
    "    num_samples, num_global_experts = int(scores_w_noise.size(0)), int(scores_w_noise.size(1))\n",
    "    mask = _one_hot_with_dtype(top_ids[:, 0], num_global_experts, dtype=scores_w_noise.dtype,\n",
    "        hot_value=num_global_experts / num_samples)\n",
    "    me = torch.sum(scores_w_noise, dim=0)\n",
    "    ce = torch.sum(mask, dim=0)\n",
    "    l_aux = torch.sum(me * ce) / num_samples\n",
    "    return l_aux\n",
    "\n",
    "def load_importance_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise):\n",
    "    def load_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise):\n",
    "        assert gate_noise > 0, \"`gate_noise` must be > 0 for normalization in load_importance_loss().\"\n",
    "        normal = Normal(\n",
    "            torch.tensor([0.0], device=scores_wo_noise.device),\n",
    "            torch.tensor([gate_noise / num_global_experts], device=scores_wo_noise.device),\n",
    "        )\n",
    "        threshold = topk_logits[:, -1].view(-1, 1).float()\n",
    "        diff = scores_wo_noise.float() - threshold.float()\n",
    "        prob = normal.cdf(diff)\n",
    "        Load = prob.sum(0)\n",
    "        l_load = Load.float().var() / (Load.float().mean() ** 2 + 1e-10)\n",
    "        return l_load\n",
    "\n",
    "    def importance_loss(scores_wo_noise):\n",
    "        Impi = scores_wo_noise.float().sum(0)\n",
    "        l_imp = Impi.float().var() / (Impi.float().mean() ** 2 + 1e-10)\n",
    "\n",
    "        return l_imp\n",
    "\n",
    "    l_imp = importance_loss(scores_wo_noise)\n",
    "    l_load = load_loss(scores_wo_noise, topk_logits, num_global_experts, gate_noise)\n",
    "    return (l_imp + l_load) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd424f-6904-4146-a20c-1f42af70c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '8888'\n",
    "world_size = 8\n",
    "rank = 0\n",
    "\n",
    "dist.init_process_group(backend='nccl', init_method='env://', world_size=world_size, rank=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87c3311-b8ac-474f-9823-9fc77aa1fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_scheduler import build_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd9e9560-046f-4938-a23e-d03a94bbedf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Swin Transformer training and evaluation script --cfg FILE\n",
      "                                                       [--opts OPTS [OPTS ...]]\n",
      "                                                       [--batch-size BATCH_SIZE]\n",
      "                                                       [--data-path DATA_PATH]\n",
      "                                                       [--zip]\n",
      "                                                       [--cache-mode {no,full,part}]\n",
      "                                                       [--pretrained PRETRAINED]\n",
      "                                                       [--resume RESUME]\n",
      "                                                       [--accumulation-steps ACCUMULATION_STEPS]\n",
      "                                                       [--use-checkpoint]\n",
      "                                                       [--disable_amp]\n",
      "                                                       [--amp-opt-level {O0,O1,O2}]\n",
      "                                                       [--output PATH]\n",
      "                                                       [--tag TAG] [--eval]\n",
      "                                                       [--throughput]\n",
      "                                                       --local_rank LOCAL_RANK\n",
      "Swin Transformer training and evaluation script: error: the following arguments are required: --cfg, --local_rank\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args, config = parse_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "685267e1-a637-433e-80d7-45746ddac6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available objects for config:\n",
      "     AliasManager\n",
      "     DisplayFormatter\n",
      "     HistoryManager\n",
      "     IPCompleter\n",
      "     IPKernelApp\n",
      "     LoggingMagics\n",
      "     MagicsManager\n",
      "     OSMagics\n",
      "     PrefilterManager\n",
      "     ScriptMagics\n",
      "     StoreMagics\n",
      "     ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5083abb2-f94c-42a0-b314-c49d53901dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mbuild_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mbuild_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_EPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecay_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDECAY_EPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmulti_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_iter_per_epoch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTISTEPS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCosineLRScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_initial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_PREFIX\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_mul\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlr_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_lr_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcycle_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_in_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_PREFIX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearLRScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_initial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mlr_min_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_lr_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_in_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLRScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecay_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDECAY_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_lr_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_in_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multistep'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiStepLRScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmilestones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_lr_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARMUP_LR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarmup_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mt_in_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /zihao/zihao/MoE/Swin-Transformer/lr_scheduler.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??build_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd44194-928d-4a9a-9861-e196de1ab6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
